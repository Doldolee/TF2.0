{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "cat-dog-finetuning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolDolSee/TF2.0/blob/main/cat_dog_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-12-16T06:25:58.256456Z",
          "iopub.execute_input": "2021-12-16T06:25:58.257198Z",
          "iopub.status.idle": "2021-12-16T06:26:01.191936Z",
          "shell.execute_reply.started": "2021-12-16T06:25:58.257092Z",
          "shell.execute_reply": "2021-12-16T06:26:01.191221Z"
        },
        "trusted": true,
        "id": "UAR8Y8RwNfuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "def make_catndog_dataframe():\n",
        "    paths = []\n",
        "    dataset_gubuns = []\n",
        "    label_gubuns = []\n",
        "    # os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n",
        "    # cat-and-dog 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n",
        "    # cat-and-dog 밑으로 /train/, /test/ 하위 디렉토리 존재(학습, 테스트 용 이미지 파일들을 가짐)\n",
        "\n",
        "    for dirname, _, filenames in os.walk('/kaggle/input/cat-and-dog'):\n",
        "        for filename in filenames:\n",
        "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
        "            if '.jpg' in filename:\n",
        "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
        "                file_path = dirname+'/'+ filename\n",
        "                paths.append(file_path)\n",
        "                # 파일의 절대 경로에 training_set, test_set가 포함되어 있으면 데이터 세트 구분을 'train'과 'test'로 분류. \n",
        "                if '/training_set/' in file_path:\n",
        "                    dataset_gubuns.append('train')  \n",
        "                elif '/test_set/' in file_path:\n",
        "                    dataset_gubuns.append('test')\n",
        "                else: dataset_gubuns.append('N/A')\n",
        "\n",
        "                # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n",
        "                if 'dogs' in file_path:\n",
        "                    label_gubuns.append('DOG')\n",
        "                elif 'cats' in file_path:\n",
        "                    label_gubuns.append('CAT')\n",
        "                else: label_gubuns.append('N/A')\n",
        "    \n",
        "    data_df = pd.DataFrame({'path':paths, 'dataset':dataset_gubuns, 'label':label_gubuns})\n",
        "    return data_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T06:26:01.193682Z",
          "iopub.execute_input": "2021-12-16T06:26:01.193928Z",
          "iopub.status.idle": "2021-12-16T06:26:01.202022Z",
          "shell.execute_reply.started": "2021-12-16T06:26:01.193894Z",
          "shell.execute_reply": "2021-12-16T06:26:01.201042Z"
        },
        "trusted": true,
        "id": "-aWcAtOeNfus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = make_catndog_dataframe()\n",
        "data_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T06:26:01.203316Z",
          "iopub.execute_input": "2021-12-16T06:26:01.203593Z",
          "iopub.status.idle": "2021-12-16T06:26:01.280468Z",
          "shell.execute_reply.started": "2021-12-16T06:26:01.203559Z",
          "shell.execute_reply": "2021-12-16T06:26:01.279796Z"
        },
        "trusted": true,
        "id": "nMMelCBsNfut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn\n",
        "import cv2\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE=160\n",
        "\n",
        "class CnD_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, batch_size=BATCH_SIZE, augmentor=None,shuffle=False, pre_func = None):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames)/BATCH_SIZE))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환.\n",
        "    def __getitem__(self, index):\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정.\n",
        "        image_batch = np.zeros((image_name_batch.shape[0],IMAGE_SIZE, IMAGE_SIZE,3), dtype='float32')\n",
        "        \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "                \n",
        "            image_batch[image_index]=image\n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            \n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:22:35.573711Z",
          "iopub.execute_input": "2021-12-16T07:22:35.573988Z",
          "iopub.status.idle": "2021-12-16T07:22:35.587056Z",
          "shell.execute_reply.started": "2021-12-16T07:22:35.573952Z",
          "shell.execute_reply": "2021-12-16T07:22:35.586367Z"
        },
        "trusted": true,
        "id": "TvMeEVZDNfuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_train_valid_test(data_df):\n",
        "    train_df = data_df[data_df[\"dataset\"]==\"train\"]\n",
        "    test_df = data_df[data_df['dataset']=='test']\n",
        "    \n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.factorize(train_df['label'])[0]\n",
        "    \n",
        "    test_path = test_df['path'].values\n",
        "    test_label = pd.factorize(test_df['label'])[0]\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=0.5, random_state=2021)\n",
        "    print('학습용 path shape:', tr_path.shape, '검증용 path shape:', val_path.shape, \n",
        "      '학습용 label shape:', tr_label.shape, '검증용 label shape:', val_label.shape)\n",
        "    return tr_path, tr_label, val_path, val_label, test_path, test_label\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:22:35.706134Z",
          "iopub.execute_input": "2021-12-16T07:22:35.706770Z",
          "iopub.status.idle": "2021-12-16T07:22:35.713210Z",
          "shell.execute_reply.started": "2021-12-16T07:22:35.706734Z",
          "shell.execute_reply": "2021-12-16T07:22:35.712313Z"
        },
        "trusted": true,
        "id": "B__R7tL-Nfuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def create_model(model_name = \"mobilenet\", verbose=False):\n",
        "    input_tensor = tf.keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE,3))\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = tf.keras.applications.vgg16.VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = tf.keras.applications.ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name ==\"xception\":\n",
        "        base_model = tf.keras.applications.Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == \"mobilenet\":\n",
        "        base_model = tf.keras.applications.MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    \n",
        "    bm_output = base_model.output\n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(bm_output)\n",
        "    if model_name !=\"vgg16\":\n",
        "        x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Dense(50, activation='relu', name='fc1')(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=input_tensor, outputs=output)\n",
        "    \n",
        "    if verbose:\n",
        "        model.summary()\n",
        "    return model\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:22:35.851186Z",
          "iopub.execute_input": "2021-12-16T07:22:35.851735Z",
          "iopub.status.idle": "2021-12-16T07:22:35.860900Z",
          "shell.execute_reply.started": "2021-12-16T07:22:35.851695Z",
          "shell.execute_reply": "2021-12-16T07:22:35.860183Z"
        },
        "trusted": true,
        "id": "4ydhGz6pNfuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
        "\n",
        "def train_model(data_df, model_name, augmentor, preprocessing_func):\n",
        "    tr_path, tr_label, val_path, val_label, test_path, test_label = get_train_valid_test(data_df)\n",
        "    \n",
        "    tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor=augmentor, shuffle=True, pre_func=preprocessing_func)\n",
        "    val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=preprocessing_func)\n",
        "    \n",
        "    model= create_model(model_name=model_name)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    N_EPOCHS = 20\n",
        "    history = model.fit(tr_ds,epochs=N_EPOCHS, validation_data = val_ds, verbose=1)\n",
        "    return model, history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:22:35.981163Z",
          "iopub.execute_input": "2021-12-16T07:22:35.982068Z",
          "iopub.status.idle": "2021-12-16T07:22:35.989259Z",
          "shell.execute_reply.started": "2021-12-16T07:22:35.982012Z",
          "shell.execute_reply": "2021-12-16T07:22:35.988580Z"
        },
        "trusted": true,
        "id": "QutvpWdqNfuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습/검증/테스트로 쪼개질 데이터를 전체 데이터의 30%로 설정. \n",
        "input_df, _ = train_test_split(data_df, test_size=0.7, random_state=2021)\n",
        "\n",
        "mobile_model, mobile_history = train_model(input_df, 'mobilenet', None, mobile_preprocess_input)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:22:36.122978Z",
          "iopub.execute_input": "2021-12-16T07:22:36.123236Z",
          "iopub.status.idle": "2021-12-16T07:25:50.160682Z",
          "shell.execute_reply.started": "2021-12-16T07:22:36.123208Z",
          "shell.execute_reply": "2021-12-16T07:25:50.159894Z"
        },
        "trusted": true,
        "id": "BYa52cIFNfux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = data_df[data_df['dataset']=='test']\n",
        "test_path = test_df['path'].values\n",
        "test_label = pd.factorize(test_df['label'])[0]\n",
        "\n",
        "test_ds = CnD_Dataset(test_path, test_label, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=mobile_preprocess_input)\n",
        "mobile_model.evaluate(test_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:25:50.162692Z",
          "iopub.execute_input": "2021-12-16T07:25:50.162941Z",
          "iopub.status.idle": "2021-12-16T07:26:03.889542Z",
          "shell.execute_reply.started": "2021-12-16T07:25:50.162907Z",
          "shell.execute_reply": "2021-12-16T07:26:03.888867Z"
        },
        "trusted": true,
        "id": "gFvJCRjrNfuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(model_name='mobilenet')\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:30:31.308699Z",
          "iopub.execute_input": "2021-12-16T07:30:31.309296Z",
          "iopub.status.idle": "2021-12-16T07:30:32.317028Z",
          "shell.execute_reply.started": "2021-12-16T07:30:31.309240Z",
          "shell.execute_reply": "2021-12-16T07:30:32.316319Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "N6ey4_7ZNfuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:30:42.725155Z",
          "iopub.execute_input": "2021-12-16T07:30:42.725679Z",
          "iopub.status.idle": "2021-12-16T07:30:42.738360Z",
          "shell.execute_reply.started": "2021-12-16T07:30:42.725641Z",
          "shell.execute_reply": "2021-12-16T07:30:42.737301Z"
        },
        "trusted": true,
        "id": "Ik4vb715Nfuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[-4:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:30:54.953982Z",
          "iopub.execute_input": "2021-12-16T07:30:54.954270Z",
          "iopub.status.idle": "2021-12-16T07:30:54.959923Z",
          "shell.execute_reply.started": "2021-12-16T07:30:54.954225Z",
          "shell.execute_reply": "2021-12-16T07:30:54.959301Z"
        },
        "trusted": true,
        "id": "6hlP5jtUNfuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.name, 'trainable:', layer.trainable)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:35:11.873232Z",
          "iopub.execute_input": "2021-12-16T07:35:11.873509Z",
          "iopub.status.idle": "2021-12-16T07:35:11.941119Z",
          "shell.execute_reply.started": "2021-12-16T07:35:11.873479Z",
          "shell.execute_reply": "2021-12-16T07:35:11.940462Z"
        },
        "trusted": true,
        "id": "Hrb6OmBTNfu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-4]:\n",
        "    layer.trainable=False\n",
        "    print(layer.name, 'trainable:', layer.trainable)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:36:57.077964Z",
          "iopub.execute_input": "2021-12-16T07:36:57.078216Z",
          "iopub.status.idle": "2021-12-16T07:36:57.156628Z",
          "shell.execute_reply.started": "2021-12-16T07:36:57.078187Z",
          "shell.execute_reply": "2021-12-16T07:36:57.155925Z"
        },
        "trusted": true,
        "id": "AuAX4jaDNfu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n### final 4 layers ### ')\n",
        "for layer in model.layers[-4:]:\n",
        "    print(layer.name, 'trainable:', layer.trainable)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:37:01.209841Z",
          "iopub.execute_input": "2021-12-16T07:37:01.210099Z",
          "iopub.status.idle": "2021-12-16T07:37:01.218613Z",
          "shell.execute_reply.started": "2021-12-16T07:37:01.210059Z",
          "shell.execute_reply": "2021-12-16T07:37:01.217906Z"
        },
        "trusted": true,
        "id": "ZPI2HDnlNfu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def train_model_fine_tune(data_df, model_name, augmentor, preprocessing_func):\n",
        "    # 학습/검증/테스트용 이미지 파일 절대경로와 Label encoding 된 데이터 세트 반환\n",
        "    tr_path, tr_label, val_path, val_label, test_path, test_label = get_train_valid_test(data_df)\n",
        "    \n",
        "    # 학습과 검증용 Sequence Dataset 생성. \n",
        "    tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor=augmentor, \n",
        "                          shuffle=True, pre_func=preprocessing_func)\n",
        "    val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE, augmentor=None, \n",
        "                           shuffle=False, pre_func=preprocessing_func)\n",
        "    \n",
        "    # 입력된 model_name에 따라 모델 생성. \n",
        "    model = create_model(model_name=model_name)\n",
        "    # 최종 output 출력을 softmax에서 sigmoid로 변환되었으므로 binary_crossentropy로 변환 \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # feature extractor layer들을 freeze\n",
        "    for layer in model.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    FIRST_EPOCHS = 10\n",
        "    SECOND_EPOCHS = 10\n",
        "    # 1단계 fine tuning 학습 수행. \n",
        "    history = model.fit(tr_ds, epochs=FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                       verbose=1)\n",
        "    # 전체 layer들을 unfreeze, 단 batch normalization layer는 그대로 freeze\n",
        "    for layer in model.layers:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "    # 2단계는 learning rate를 기존 보다 1/10 감소    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.00001), loss='binary_crossentropy', metrics=['accuracy'])    \n",
        "    history = model.fit(tr_ds, epochs=SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                       verbose=1)\n",
        "    \n",
        "    return model, history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:42:37.750703Z",
          "iopub.execute_input": "2021-12-16T07:42:37.750956Z",
          "iopub.status.idle": "2021-12-16T07:42:37.763206Z",
          "shell.execute_reply.started": "2021-12-16T07:42:37.750928Z",
          "shell.execute_reply": "2021-12-16T07:42:37.761196Z"
        },
        "trusted": true,
        "id": "V3jLgZY2Nfu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_model_tuned, mobile_tuned_history = train_model_fine_tune(input_df, 'mobilenet', None, mobile_preprocess_input)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-16T07:42:37.903610Z",
          "iopub.execute_input": "2021-12-16T07:42:37.904071Z",
          "iopub.status.idle": "2021-12-16T07:46:27.905398Z",
          "shell.execute_reply.started": "2021-12-16T07:42:37.904036Z",
          "shell.execute_reply": "2021-12-16T07:46:27.904641Z"
        },
        "trusted": true,
        "id": "XO-_syydNfu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_model_tuned.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "O-TGXzbmNfu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}