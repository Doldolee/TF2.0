{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsfTuN6AWeR6WzRJjcec9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolDolSee/TF2.0/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCJ4hBdkeqS"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "#딥러닝에서는 실수형을 사용하기 때문에 int형에서 변경해줌\n",
        "x_train, x_test = x_train.astype(\"float32\"), x_test.astype(\"float32\")\n",
        "#flatting: 2차원 메트릭스를 1차원 벡터의 784(28*28)으로 변환해줌\n",
        "x_train, x_test = x_train.reshape([-1,784]), x_test.reshape([-1,784])\n",
        "x_train, x_test = x_train/255., x_test /255.\n",
        "\n",
        "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CALWDn4vlHL"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
        "train_data_iter = iter(train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqk0jjhSqaPL"
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    #padding=same의 의미는 원본사이즈와 동일한 사이즈의 feature map이 나오도록 강제하겠다. 라는 의미임.\n",
        "    self.conv_layer_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\")\n",
        "    self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
        "\n",
        "    self.conv_layer_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "    self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
        "\n",
        "    self.flatten_layer = tf.keras.layers.Flatten()\n",
        "    self.fc_layer_1 = tf.keras.layers.Dense(1024, activation='relu')\n",
        "\n",
        "    self.output_layer = tf.keras.layers.Dense(10, activation=None)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x_image = tf.reshape(x,[-1, 28,28,1])\n",
        "    # 28*28*1 -> 28*28*32\n",
        "    h_conv1 = self.conv_layer_1(x_image)\n",
        "    # 28*28*32 -> 14*14*32\n",
        "    h_pool1 = self.pool_layer_1(h_conv1)\n",
        "    # 14*14*32 -> 14*14*64\n",
        "    h_conv2 = self.conv_layer_2(h_pool1)\n",
        "    # 14*14*64 -> 7*7*64\n",
        "    h_pool2 = self.pool_layer_2(h_conv2)\n",
        "    # 7*7*64(3136) -> 1024\n",
        "    h_pool2_flat = self.flatten_layer(h_pool2)\n",
        "    print(h_pool2_flat)\n",
        "    h_fc1 = self.fc_layer_1(h_pool2_flat)\n",
        "    # 1024 -> 10\n",
        "    logits = self.output_layer(h_fc1)\n",
        "    y_pred = tf.nn.softmax(logits)\n",
        "\n",
        "    return y_pred, logits\n",
        "\n",
        "@tf.function\n",
        "def cross_entropy_loss(logits, y):\n",
        "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "\n",
        "optimizer = tf.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred, logits = model(x)\n",
        "    loss = cross_entropy_loss(logits,y_pred)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "@tf.function\n",
        "def compute_accuracy(y_pred, y):\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "CNN_model = CNN()\n",
        "\n",
        "for i in range(10000):\n",
        "  batch_x, batch_y = next(train_data_iter)\n",
        "  if i % 100 ==0:\n",
        "    train_accuracy = compute_accuracy(CNN_model(batch_x)[0], batch_y)\n",
        "    print(train_accuracy)\n",
        "\n",
        "  train_step(CNN_model, batch_x, batch_y)\n",
        "\n",
        "print(compute_accuracy(x_test)[0],y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zSKqOQm6Inu",
        "outputId": "b0de8f47-7888-43e4-b943-d600760a5da1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train.astype('float32'), x_test.astype(\"float32\")\n",
        "x_train, x_test = x_train/255., x_test/255.\n",
        "\n",
        "#squeeze는 더미 dimension을 없애는 api\n",
        "y_train_one_hot = tf.squeeze(tf.one_hot(y_train,10), axis=1)\n",
        "y_test_one_hot = tf.squeeze(tf.one_hot(y_test,10), axis=1)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train_one_hot))\n",
        "train_data = train_data.repeat().shuffle(50000).batch(128)\n",
        "train_data_iter = iter(train_data)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test_one_hot))\n",
        "test_data = test_data.batch(1000)\n",
        "test_data_iter = iter(test_data)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOLyCNV5MOuC",
        "outputId": "98116864-a09d-4f19-cf4c-d055ea49537b"
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv_layer_1 = tf.keras.layers.Conv2D(filters=64, kernel_size = 5, strides=1, padding=\"same\", activation=\"relu\")\n",
        "    self.Pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
        "    #64개의 특징을 64개의 특징으로 맵핑\n",
        "    self.conv_layer_2 =  tf.keras.layers.Conv2D(filters=64, kernel_size = 5, strides=1, padding=\"same\", activation=\"relu\")\n",
        "    self.Pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)\n",
        "\n",
        "    self.conv_layer_3 =  tf.keras.layers.Conv2D(filters=128, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\")\n",
        "    self.conv_layer_4 =  tf.keras.layers.Conv2D(filters=128, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\")\n",
        "    self.conv_layer_5 =  tf.keras.layers.Conv2D(filters=128, kernel_size = 3, strides=1, padding=\"same\", activation=\"relu\")\n",
        "\n",
        "    #8*8*128의 feature map을 flatten 후 384개의 특징들로 맵핑한다.\n",
        "    self.flatten_layer = tf.keras.layers.Flatten()\n",
        "    self.fc_layer_1 = tf.keras.layers.Dense(384, activation=\"relu\")\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "    #label 수 만틈 나가는 노드 지정\n",
        "    self.output_layer = tf.keras.layers.Dense(10, activation=None)\n",
        "  \n",
        "  def call(self, x, is_training):\n",
        "    h_conv1 = self.conv_layer_1(x)\n",
        "    h_pool1 = self.Pool_layer_1(h_conv1)\n",
        "    h_conv2 = self.conv_layer_2(h_pool1)\n",
        "    h_pool2 = self.Pool_layer_2(h_conv2)\n",
        "    h_conv3 = self.conv_layer_3(h_pool2)\n",
        "    h_conv4 = self.conv_layer_4(h_conv3)\n",
        "    h_conv5 = self.conv_layer_5(h_conv4)\n",
        "    h_conv5_flat = self.flatten_layer(h_conv5)\n",
        "    h_fc1 = self.fc_layer_1(h_conv5_flat)\n",
        "\n",
        "    #training할 때만 dropout적용되게 하기 위해 boolean인자인 is_training사용\n",
        "    h_fc1_drop = self.dropout(h_fc1, training = is_training)\n",
        "    logits = self.output_layer(h_fc1_drop)\n",
        "    y_pred = tf.nn.softmax(logits)\n",
        "\n",
        "    return y_pred, logits\n",
        "\n",
        "@tf.function\n",
        "def cross_entropy_loss(logits, y):\n",
        "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "\n",
        "optimizer = tf.optimizers.RMSprop(1e-3)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x,y, is_training):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred, logits = model(x, is_training)\n",
        "    loss = cross_entropy_loss(logits, y)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "@tf.function\n",
        "def compute_accuracy(y_pred, y):\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "CNN_model = CNN()\n",
        "\n",
        "for i in range(10000):\n",
        "  batch_x, batch_y = next(train_data_iter)\n",
        "\n",
        "  if i % 100 ==0:\n",
        "    train_accuracy = compute_accuracy(CNN_model(batch_x, False)[0], batch_y)\n",
        "    loss_print = cross_entropy_loss(CNN_model(batch_x, False)[1], batch_y)\n",
        "\n",
        "    print(train_accuracy, loss_print)\n",
        "\n",
        "  train_step(CNN_model, batch_x, batch_y, True)\n",
        "\n",
        "test_accuracy = 0.0\n",
        "for i in range(10):\n",
        "  test_batch_x, test_batch_y = next(test_data_iter)\n",
        "  test_accuracy = test_accuracy + compute_accuracy(CNN_model(test_batch_x, False)[0], test_batch_y).numpy()\n",
        "test_accuracy = test_accuracy/10\n",
        "print(test_accuracy)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.0625, shape=(), dtype=float32) tf.Tensor(2.3048513, shape=(), dtype=float32)\n",
            "tf.Tensor(0.25, shape=(), dtype=float32) tf.Tensor(1.9656091, shape=(), dtype=float32)\n",
            "tf.Tensor(0.390625, shape=(), dtype=float32) tf.Tensor(1.7277498, shape=(), dtype=float32)\n",
            "tf.Tensor(0.3671875, shape=(), dtype=float32) tf.Tensor(1.7669963, shape=(), dtype=float32)\n",
            "tf.Tensor(0.484375, shape=(), dtype=float32) tf.Tensor(1.4062089, shape=(), dtype=float32)\n",
            "tf.Tensor(0.390625, shape=(), dtype=float32) tf.Tensor(1.5893736, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6171875, shape=(), dtype=float32) tf.Tensor(1.2298894, shape=(), dtype=float32)\n",
            "tf.Tensor(0.578125, shape=(), dtype=float32) tf.Tensor(1.1573594, shape=(), dtype=float32)\n",
            "tf.Tensor(0.609375, shape=(), dtype=float32) tf.Tensor(1.1268064, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5625, shape=(), dtype=float32) tf.Tensor(1.33607, shape=(), dtype=float32)\n",
            "tf.Tensor(0.65625, shape=(), dtype=float32) tf.Tensor(0.9870999, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6484375, shape=(), dtype=float32) tf.Tensor(0.9756085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6796875, shape=(), dtype=float32) tf.Tensor(0.8983512, shape=(), dtype=float32)\n",
            "tf.Tensor(0.671875, shape=(), dtype=float32) tf.Tensor(0.8831481, shape=(), dtype=float32)\n",
            "tf.Tensor(0.703125, shape=(), dtype=float32) tf.Tensor(0.753584, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7109375, shape=(), dtype=float32) tf.Tensor(0.773892, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7265625, shape=(), dtype=float32) tf.Tensor(0.77048355, shape=(), dtype=float32)\n",
            "tf.Tensor(0.71875, shape=(), dtype=float32) tf.Tensor(0.7677333, shape=(), dtype=float32)\n",
            "tf.Tensor(0.734375, shape=(), dtype=float32) tf.Tensor(0.82327986, shape=(), dtype=float32)\n",
            "tf.Tensor(0.75, shape=(), dtype=float32) tf.Tensor(0.6489167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8046875, shape=(), dtype=float32) tf.Tensor(0.54247504, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7890625, shape=(), dtype=float32) tf.Tensor(0.49062493, shape=(), dtype=float32)\n",
            "tf.Tensor(0.796875, shape=(), dtype=float32) tf.Tensor(0.50900716, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8125, shape=(), dtype=float32) tf.Tensor(0.5747071, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8359375, shape=(), dtype=float32) tf.Tensor(0.5298126, shape=(), dtype=float32)\n",
            "tf.Tensor(0.796875, shape=(), dtype=float32) tf.Tensor(0.6362351, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7890625, shape=(), dtype=float32) tf.Tensor(0.66181886, shape=(), dtype=float32)\n",
            "tf.Tensor(0.84375, shape=(), dtype=float32) tf.Tensor(0.4018641, shape=(), dtype=float32)\n",
            "tf.Tensor(0.890625, shape=(), dtype=float32) tf.Tensor(0.35174558, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8671875, shape=(), dtype=float32) tf.Tensor(0.42362276, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8984375, shape=(), dtype=float32) tf.Tensor(0.4416458, shape=(), dtype=float32)\n",
            "tf.Tensor(0.90625, shape=(), dtype=float32) tf.Tensor(0.36961433, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.22070529, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8828125, shape=(), dtype=float32) tf.Tensor(0.31573167, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8828125, shape=(), dtype=float32) tf.Tensor(0.38136053, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8828125, shape=(), dtype=float32) tf.Tensor(0.2722831, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.21317834, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.2070915, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8984375, shape=(), dtype=float32) tf.Tensor(0.29718322, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8515625, shape=(), dtype=float32) tf.Tensor(0.48085925, shape=(), dtype=float32)\n",
            "tf.Tensor(0.84375, shape=(), dtype=float32) tf.Tensor(0.40326622, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.21498802, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9453125, shape=(), dtype=float32) tf.Tensor(0.25775093, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.210763, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9453125, shape=(), dtype=float32) tf.Tensor(0.1434155, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.28980723, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9140625, shape=(), dtype=float32) tf.Tensor(0.18752223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.21196881, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.17530803, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.1590047, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.22719532, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.301372, shape=(), dtype=float32)\n",
            "tf.Tensor(0.90625, shape=(), dtype=float32) tf.Tensor(0.22959986, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.18988116, shape=(), dtype=float32)\n",
            "tf.Tensor(0.96875, shape=(), dtype=float32) tf.Tensor(0.13405862, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.23157184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9453125, shape=(), dtype=float32) tf.Tensor(0.18789345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.984375, shape=(), dtype=float32) tf.Tensor(0.16298607, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.19210483, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9140625, shape=(), dtype=float32) tf.Tensor(0.23653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.42407447, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.1963773, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9765625, shape=(), dtype=float32) tf.Tensor(0.07433191, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.14779004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.26775968, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.21404347, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9609375, shape=(), dtype=float32) tf.Tensor(0.14019476, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.14959066, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.12894526, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.09211193, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9453125, shape=(), dtype=float32) tf.Tensor(0.1476489, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.20363772, shape=(), dtype=float32)\n",
            "tf.Tensor(0.875, shape=(), dtype=float32) tf.Tensor(0.3749659, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.20079516, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.19057782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.19053532, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.20413634, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8828125, shape=(), dtype=float32) tf.Tensor(0.43473166, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.1448439, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8984375, shape=(), dtype=float32) tf.Tensor(0.28846043, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9453125, shape=(), dtype=float32) tf.Tensor(0.17566906, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.30073798, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8984375, shape=(), dtype=float32) tf.Tensor(0.35354137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9609375, shape=(), dtype=float32) tf.Tensor(0.13970485, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9609375, shape=(), dtype=float32) tf.Tensor(0.0961863, shape=(), dtype=float32)\n",
            "tf.Tensor(0.90625, shape=(), dtype=float32) tf.Tensor(0.2361022, shape=(), dtype=float32)\n",
            "tf.Tensor(0.859375, shape=(), dtype=float32) tf.Tensor(0.8955025, shape=(), dtype=float32)\n",
            "tf.Tensor(0.828125, shape=(), dtype=float32) tf.Tensor(0.56528836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9140625, shape=(), dtype=float32) tf.Tensor(0.4086281, shape=(), dtype=float32)\n",
            "tf.Tensor(0.921875, shape=(), dtype=float32) tf.Tensor(0.23430714, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.12683037, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8984375, shape=(), dtype=float32) tf.Tensor(0.39923686, shape=(), dtype=float32)\n",
            "tf.Tensor(0.8671875, shape=(), dtype=float32) tf.Tensor(0.42083216, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.4121338, shape=(), dtype=float32)\n",
            "tf.Tensor(0.7734375, shape=(), dtype=float32) tf.Tensor(0.81207573, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.33540195, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9609375, shape=(), dtype=float32) tf.Tensor(0.1878962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9375, shape=(), dtype=float32) tf.Tensor(0.32625034, shape=(), dtype=float32)\n",
            "tf.Tensor(0.9296875, shape=(), dtype=float32) tf.Tensor(0.41174623, shape=(), dtype=float32)\n",
            "tf.Tensor(0.953125, shape=(), dtype=float32) tf.Tensor(0.15344478, shape=(), dtype=float32)\n",
            "0.68960000872612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDN0PBVnXbhB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}