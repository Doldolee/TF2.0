{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "catndog-sequence.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolDolSee/TF2.0/blob/main/catndog_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-25T16:50:01.456831Z",
          "iopub.execute_input": "2021-11-25T16:50:01.457522Z",
          "iopub.status.idle": "2021-11-25T16:50:08.392515Z",
          "shell.execute_reply.started": "2021-11-25T16:50:01.457425Z",
          "shell.execute_reply": "2021-11-25T16:50:08.391830Z"
        },
        "trusted": true,
        "id": "xsrNMPDfUTFK"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T16:50:08.394902Z",
          "iopub.execute_input": "2021-11-25T16:50:08.395178Z",
          "iopub.status.idle": "2021-11-25T16:50:08.404256Z",
          "shell.execute_reply.started": "2021-11-25T16:50:08.395150Z",
          "shell.execute_reply": "2021-11-25T16:50:08.403575Z"
        },
        "trusted": true,
        "id": "4VVtfZ5oUTFO"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "def make_catndog_dataframe():\n",
        "    paths = []\n",
        "    dataset_gubuns = []\n",
        "    label_gubuns = []\n",
        "    # os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n",
        "    # cat-and-dog 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n",
        "    # cat-and-dog 밑으로 /train/, /test/ 하위 디렉토리 존재(학습, 테스트 용 이미지 파일들을 가짐)\n",
        "\n",
        "    for dirname, _, filenames in os.walk('/kaggle/input/cat-and-dog'):\n",
        "        for filename in filenames:\n",
        "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
        "            if '.jpg' in filename:\n",
        "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
        "                file_path = dirname+'/'+ filename\n",
        "                paths.append(file_path)\n",
        "                # 파일의 절대 경로에 training_set, test_set가 포함되어 있으면 데이터 세트 구분을 'train'과 'test'로 분류. \n",
        "                if '/training_set/' in file_path:\n",
        "                    dataset_gubuns.append('train')  \n",
        "                elif '/test_set/' in file_path:\n",
        "                    dataset_gubuns.append('test')\n",
        "                else: dataset_gubuns.append('N/A')\n",
        "\n",
        "                # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n",
        "                if 'dogs' in file_path:\n",
        "                    label_gubuns.append('DOG')\n",
        "                elif 'cats' in file_path:\n",
        "                    label_gubuns.append('CAT')\n",
        "                else: label_gubuns.append('N/A')\n",
        "    \n",
        "    data_df = pd.DataFrame({'path':paths, 'dataset':dataset_gubuns, 'label':label_gubuns})\n",
        "    return data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T16:50:08.405419Z",
          "iopub.execute_input": "2021-11-25T16:50:08.405781Z",
          "iopub.status.idle": "2021-11-25T16:50:09.088811Z",
          "shell.execute_reply.started": "2021-11-25T16:50:08.405746Z",
          "shell.execute_reply": "2021-11-25T16:50:09.088106Z"
        },
        "trusted": true,
        "id": "rkX2WW3OUTFP"
      },
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "data_df = make_catndog_dataframe()\n",
        "print('data_df shape:', data_df.shape)\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:14:43.169029Z",
          "iopub.execute_input": "2021-11-25T17:14:43.169418Z",
          "iopub.status.idle": "2021-11-25T17:14:43.183340Z",
          "shell.execute_reply.started": "2021-11-25T17:14:43.169381Z",
          "shell.execute_reply": "2021-11-25T17:14:43.182611Z"
        },
        "trusted": true,
        "id": "yfX63_0SUTFQ"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn\n",
        "import cv2\n",
        "\n",
        "BATCH_SIZE=64\n",
        "IMAGE_SIZE=224\n",
        "\n",
        "class CnD_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            pass\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels)/self.batch_size))\n",
        "    \n",
        "    #index는 batch단위로 가져오는 step의 index\n",
        "    def __getitem__(self, index):\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "            \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image,(IMAGE_SIZE, IMAGE_SIZE))\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image = image)['image']\n",
        "            image_batch[image_index]=image\n",
        "        return image_batch, label_batch\n",
        "            \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames,self.labels)\n",
        "        else:\n",
        "            pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:14:43.390292Z",
          "iopub.execute_input": "2021-11-25T17:14:43.390649Z",
          "iopub.status.idle": "2021-11-25T17:14:43.401725Z",
          "shell.execute_reply.started": "2021-11-25T17:14:43.390619Z",
          "shell.execute_reply": "2021-11-25T17:14:43.401009Z"
        },
        "trusted": true,
        "id": "2JHXVLN_UTFR"
      },
      "source": [
        "import albumentations as A\n",
        "\n",
        "\n",
        "train_df = data_df[data_df['dataset']=='train']\n",
        "test_df = data_df[data_df['dataset']=='test']\n",
        "\n",
        "# image file의 위치가 있는 데이터와 label값을 numpy array로 변환. \n",
        "train_image_filenames = train_df['path'].values\n",
        "train_image_labels = train_df['label'].values\n",
        "\n",
        "cnd_augmentor = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.5)\n",
        "])\n",
        " \n",
        "cnd_ds = CnD_Dataset(train_image_filenames, train_image_labels, batch_size=BATCH_SIZE, augmentor=cnd_augmentor, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:14:43.901437Z",
          "iopub.execute_input": "2021-11-25T17:14:43.902134Z",
          "iopub.status.idle": "2021-11-25T17:14:44.851927Z",
          "shell.execute_reply.started": "2021-11-25T17:14:43.902092Z",
          "shell.execute_reply": "2021-11-25T17:14:44.851156Z"
        },
        "trusted": true,
        "id": "Kqb_NpSNUTFS"
      },
      "source": [
        "image_batch = next(iter(cnd_ds))[0]\n",
        "labels_batch = next(iter(cnd_ds))[1]\n",
        "print(image_batch.shape, labels_batch.shape)\n",
        "print(image_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:15:56.651222Z",
          "iopub.execute_input": "2021-11-25T17:15:56.651493Z",
          "iopub.status.idle": "2021-11-25T17:15:57.180607Z",
          "shell.execute_reply.started": "2021-11-25T17:15:56.651462Z",
          "shell.execute_reply": "2021-11-25T17:15:57.179942Z"
        },
        "trusted": true,
        "id": "XwoxsvckUTFS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "def show_grid_images(image_batch, ncols=4, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        # image_batch는 float형이므로 int형으로 변경하여 이미지 시각화\n",
        "        axs[i].imshow(np.array(image_batch[i], dtype='int32'))\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(title[i]) \n",
        "        \n",
        "show_grid_images(image_batch, ncols=6, title='augmented ' + labels_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCqO1jDpUTFT"
      },
      "source": [
        "scaling 감안하여 재작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:17:22.045481Z",
          "iopub.execute_input": "2021-11-25T17:17:22.045761Z",
          "iopub.status.idle": "2021-11-25T17:17:22.057534Z",
          "shell.execute_reply.started": "2021-11-25T17:17:22.045729Z",
          "shell.execute_reply": "2021-11-25T17:17:22.056662Z"
        },
        "trusted": true,
        "id": "Uy_UQNNxUTFU"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn\n",
        "import cv2\n",
        "\n",
        "BATCH_SIZE=64\n",
        "IMAGE_SIZE=224\n",
        "\n",
        "class CnD_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False):\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            pass\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels)/self.batch_size))\n",
        "    \n",
        "    #index는 batch단위로 가져오는 step의 index\n",
        "    def __getitem__(self, index):\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "            \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image,(IMAGE_SIZE, IMAGE_SIZE))\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image = image)['image']\n",
        "            image = image/255.0\n",
        "            image_batch[image_index]=image\n",
        "        return image_batch, label_batch\n",
        "            \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames,self.labels)\n",
        "        else:\n",
        "            pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:17:35.630539Z",
          "iopub.execute_input": "2021-11-25T17:17:35.631108Z",
          "iopub.status.idle": "2021-11-25T17:17:36.220310Z",
          "shell.execute_reply.started": "2021-11-25T17:17:35.631066Z",
          "shell.execute_reply": "2021-11-25T17:17:36.219579Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "hcJnD3QTUTFV"
      },
      "source": [
        "image_batch = next(iter(cnd_ds))[0]\n",
        "labels_batch = next(iter(cnd_ds))[1]\n",
        "print(image_batch.shape, labels_batch.shape)\n",
        "print(image_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:21:01.239661Z",
          "iopub.execute_input": "2021-11-25T17:21:01.240133Z",
          "iopub.status.idle": "2021-11-25T17:21:01.252266Z",
          "shell.execute_reply.started": "2021-11-25T17:21:01.240093Z",
          "shell.execute_reply": "2021-11-25T17:21:01.251405Z"
        },
        "trusted": true,
        "id": "4pBOeCkBUTFW"
      },
      "source": [
        "# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. \n",
        "class CnD_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "\n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            pass\n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.labels)/self.batch_size))\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "    \n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n",
        "        \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:21:04.103262Z",
          "iopub.execute_input": "2021-11-25T17:21:04.103522Z",
          "iopub.status.idle": "2021-11-25T17:21:04.655634Z",
          "shell.execute_reply.started": "2021-11-25T17:21:04.103491Z",
          "shell.execute_reply": "2021-11-25T17:21:04.654924Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "UIf4JEzJUTFX"
      },
      "source": [
        "cnd_augmentor = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.5)\n",
        "])\n",
        "\n",
        "def zero_one_scaler(image):\n",
        "    return image/255.0\n",
        "\n",
        "cnd_ds = CnD_Dataset(train_image_filenames, train_image_labels, batch_size=BATCH_SIZE, \n",
        "                         augmentor=cnd_augmentor, shuffle=False, pre_func=zero_one_scaler)\n",
        "images_batch = next(iter(cnd_ds))[0]\n",
        "labels_batch = next(iter(cnd_ds))[1]\n",
        "\n",
        "images_batch[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:21:30.006011Z",
          "iopub.execute_input": "2021-11-25T17:21:30.006681Z",
          "iopub.status.idle": "2021-11-25T17:21:30.661407Z",
          "shell.execute_reply.started": "2021-11-25T17:21:30.006642Z",
          "shell.execute_reply": "2021-11-25T17:21:30.660626Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "NBTxOsZdUTFX"
      },
      "source": [
        "cnd_augmentor_normalized = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.5),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "cnd_ds = CnD_Dataset(train_image_filenames, train_image_labels, batch_size=BATCH_SIZE, \n",
        "                         augmentor=cnd_augmentor_normalized, shuffle=False, pre_func=None)\n",
        "images_batch = next(iter(cnd_ds))[0]\n",
        "labels_batch = next(iter(cnd_ds))[1]\n",
        "images_batch[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBvasAa-UTFX"
      },
      "source": [
        "원핫 & 레이블 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:24:42.205437Z",
          "iopub.execute_input": "2021-11-25T17:24:42.205793Z",
          "iopub.status.idle": "2021-11-25T17:24:42.221463Z",
          "shell.execute_reply.started": "2021-11-25T17:24:42.205758Z",
          "shell.execute_reply": "2021-11-25T17:24:42.220597Z"
        },
        "trusted": true,
        "id": "c5VSO89dUTFY"
      },
      "source": [
        "labels_ohe = pd.get_dummies(train_df['label']).values\n",
        "print(labels_ohe[:5])\n",
        "\n",
        "labels_enc = pd.factorize(train_df['label'])[0]\n",
        "print(labels_enc[:5])\n",
        "\n",
        "print(labels_ohe.shape, labels_enc.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:24:51.826007Z",
          "iopub.execute_input": "2021-11-25T17:24:51.826275Z",
          "iopub.status.idle": "2021-11-25T17:24:51.843844Z",
          "shell.execute_reply.started": "2021-11-25T17:24:51.826247Z",
          "shell.execute_reply": "2021-11-25T17:24:51.842902Z"
        },
        "trusted": true,
        "id": "NZCufMKMUTFY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = data_df[data_df['dataset']=='train']\n",
        "test_df = data_df[data_df['dataset']=='test']\n",
        "\n",
        "train_path = train_df['path'].values\n",
        "train_label = pd.factorize(train_df['label'])[0]\n",
        "\n",
        "\n",
        "tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=0.15, random_state=2021)\n",
        "print('학습용 path shape:', tr_path.shape, '검증용 path shape:', val_path.shape, \n",
        "      '학습용 label shape:', tr_label.shape, '검증용 label shape:', val_label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:24:55.864053Z",
          "iopub.execute_input": "2021-11-25T17:24:55.864344Z",
          "iopub.status.idle": "2021-11-25T17:24:55.870271Z",
          "shell.execute_reply.started": "2021-11-25T17:24:55.864313Z",
          "shell.execute_reply": "2021-11-25T17:24:55.869358Z"
        },
        "trusted": true,
        "id": "tEVpsQeQUTFZ"
      },
      "source": [
        "cnd_augmentor = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    #A.VerticalFlip(p=0.5),\n",
        "    #A.ShiftScaleRotate(p=0.5)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:25:32.968900Z",
          "iopub.execute_input": "2021-11-25T17:25:32.969529Z",
          "iopub.status.idle": "2021-11-25T17:25:34.242011Z",
          "shell.execute_reply.started": "2021-11-25T17:25:32.969492Z",
          "shell.execute_reply": "2021-11-25T17:25:34.241182Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "gPkv5j-pUTFZ"
      },
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "\n",
        "tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor=cnd_augmentor, \n",
        "                      shuffle=True, pre_func=xcp_preprocess_input)\n",
        "val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE, augmentor=None, \n",
        "                       shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "tr_image_batch = next(iter(tr_ds))[0]\n",
        "val_image_batch = next(iter(val_ds))[0]\n",
        "print(tr_image_batch.shape, val_image_batch.shape)\n",
        "\n",
        "print(tr_image_batch[:1])\n",
        "print(val_image_batch[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:27:50.127441Z",
          "iopub.execute_input": "2021-11-25T17:27:50.127759Z",
          "iopub.status.idle": "2021-11-25T17:27:50.142340Z",
          "shell.execute_reply.started": "2021-11-25T17:27:50.127710Z",
          "shell.execute_reply": "2021-11-25T17:27:50.141548Z"
        },
        "trusted": true,
        "id": "YQEhWSgMUTFZ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import Xception, MobileNetV2\n",
        "\n",
        "def create_model(model_name='vgg16', verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'mobilenet':\n",
        "        base_model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    \n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    if model_name != 'vgg16':\n",
        "        x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    output = Dense(1, activation='sigmoid', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    \n",
        "    if verbose:\n",
        "        model.summary()\n",
        "        \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:28:00.073227Z",
          "iopub.execute_input": "2021-11-25T17:28:00.073482Z",
          "iopub.status.idle": "2021-11-25T17:28:04.595714Z",
          "shell.execute_reply.started": "2021-11-25T17:28:00.073453Z",
          "shell.execute_reply": "2021-11-25T17:28:04.594904Z"
        },
        "trusted": true,
        "id": "s6AYYHZSUTFZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = create_model(model_name='xception')\n",
        "model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-25T17:28:29.246380Z",
          "iopub.execute_input": "2021-11-25T17:28:29.246643Z",
          "iopub.status.idle": "2021-11-25T17:51:04.393151Z",
          "shell.execute_reply.started": "2021-11-25T17:28:29.246612Z",
          "shell.execute_reply": "2021-11-25T17:51:04.392356Z"
        },
        "trusted": true,
        "id": "CuR1A1tTUTFa"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "history = model.fit(tr_ds, epochs=N_EPOCHS, \n",
        "                    steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                    validation_data=val_ds, \n",
        "                    validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                   callbacks=([rlr_cb, ely_cb]), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdlkZLiPUTFa"
      },
      "source": [
        "test_df = data_df[data_df['dataset']=='test']\n",
        "\n",
        "test_path = test_df['path'].values\n",
        "test_label = pd.factorize(test_df['label'])[0]\n",
        "test_ds = CnD_Dataset(test_path, test_label, batch_size=BATCH_SIZE, augmentor=None, \n",
        "                       shuffle=False, pre_func=xcp_preprocess_input)\n",
        "model.evaluate(test_ds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmGZmVjBUTFa"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
        "\n",
        "def get_train_valid_test(data_df):\n",
        "    train_df = data_df[data_df['dataset']=='train']\n",
        "    test_df = data_df[data_df['dataset']=='test']\n",
        "\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.factorize(train_df['label'])[0]\n",
        "    \n",
        "    test_path = test_df['path'].values\n",
        "    test_label = pd.factorize(test_df['label'])[0]\n",
        "\n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=0.15, random_state=2021)\n",
        "    \n",
        "    return tr_path, tr_label, val_path, val_label, test_path, test_label\n",
        "    \n",
        "    \n",
        "def do_train_evaluation(data_df, model_name, augmentor, preprocessing_func):\n",
        "    tr_path, tr_label, val_path, val_label, test_path, test_label = get_train_valid_test(data_df)\n",
        "    \n",
        "    tr_ds = CnD_Dataset(tr_path, tr_label, batch_size=BATCH_SIZE, augmentor=augmentor, \n",
        "                          shuffle=True, pre_func=preprocessing_func)\n",
        "    val_ds = CnD_Dataset(val_path, val_label, batch_size=BATCH_SIZE, augmentor=None, \n",
        "                           shuffle=False, pre_func=preprocessing_func)\n",
        "    \n",
        "    model = create_model(model_name=model_name)\n",
        "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n",
        "\n",
        "    N_EPOCHS = 15\n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                       callbacks=([rlr_cb, ely_cb]), verbose=1)\n",
        "    \n",
        "    test_ds = CnD_Dataset(test_path, test_label, batch_size=BATCH_SIZE, augmentor=None, \n",
        "                           shuffle=False, pre_func=preprocessing_func)\n",
        "\n",
        "    evaluation_result = model.evaluate(test_ds)\n",
        "    print(evaluation_result)\n",
        "    return history, evaluation_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNxEZVrgUTFb"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "cnd_augmentor1 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.RandomBrightnessContrast(p=0.2)\n",
        "])\n",
        "\n",
        "history1, result1 = do_train_evaluation(data_df, 'mobilenet', cnd_augmentor1, mobile_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}